{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e4b2af",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we implement the entire process of simulating data science problem-solving with role-playing chatbots. The complete system consists of a scenario generator, a client-data scientist dual-chatbot module, as well as an assessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f214bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "import utilities\n",
    "import os\n",
    "\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2437bf",
   "metadata": {},
   "source": [
    "### 1. Abstract base class\n",
    "\n",
    "We create an `LLMBot` abstract base class to define the common methods shared by various bots we will define later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23257e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMBot(ABC):\n",
    "    \"\"\"Class definition for a single LLM bot\"\"\"\n",
    "    \n",
    "    def __init__(self, endpoint_type, temperature):\n",
    "        \"\"\"Initialize the large language model and its associated memory.\n",
    "\n",
    "        Args:\n",
    "        --------------\n",
    "        endpoint_type: \"chat\" or \"completion\".\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"        \n",
    "        # Instantiate llm\n",
    "        # Reminder: need to set up openAI API key \n",
    "        # (e.g., via environment variable OPENAI_API_KEY)\n",
    "        if endpoint_type == 'chat':\n",
    "            self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", \n",
    "                                temperature=temperature)\n",
    "        elif endpoint_type == 'completion':\n",
    "            self.llm = OpenAI(model_name=\"text-davinci-003\", \n",
    "                            temperature=temperature)\n",
    "        else:\n",
    "            raise KeyError(\"Currently unsupported endpoint type!\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def instruct(self):\n",
    "        \"\"\"Determine the context of LLM bot behavior. \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        \"\"\"Response produced by the LLM bot. \n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c477c1",
   "metadata": {},
   "source": [
    "### 2. Scenario generator\n",
    "\n",
    "The main purpose of the scenario generator bot is to generate detailed description of a concrete data science project. We divide this task into two steps, where the first step is to generate a draft description of the scenario, and the second step is to fill in the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioGenerator(LLMBot):\n",
    "\n",
    "    industry_specifics = {\n",
    "        'healthcare': \"\"\"types of patients treated (e.g., age, medical conditions), \n",
    "        common treatments and procedures, challenges faced in patient care, medical equipment used.\"\"\",\n",
    "        \n",
    "        'finance': \"\"\"types of financial products and services offered, \n",
    "        common financial transactions, challenges faced in fraud detection, \n",
    "        tools and technologies used for financial analysis.\"\"\",\n",
    "        \n",
    "        'retail': \"\"\"types of products sold, common sales channels (e.g., online, in-store), \n",
    "        challenges faced in inventory management, tools and technologies used for sales analysis.\"\"\",\n",
    "        \n",
    "        'technology': \"\"\"types of technology products or services offered, \n",
    "        common challenges faced in product development, tools and technologies \n",
    "        used for data analysis and product testing.\"\"\",\n",
    "        \n",
    "        'manufacturing': \"\"\"types of products manufactured, machines used in the production process, \n",
    "        common issues faced by the company, tools and technologies used for quality control.\"\"\",\n",
    "        \n",
    "        'transportation': \"\"\"types of transportation services provided, \n",
    "        common routes and destinations, challenges faced in route optimization, \n",
    "        tools and technologies used for vehicle maintenance and monitoring.\"\"\",\n",
    "        \n",
    "        'energy': \"\"\"types of energy produced (e.g., renewable, non-renewable), \n",
    "        common challenges faced in energy production and distribution, \n",
    "        tools and technologies used for energy monitoring and analysis.\"\"\",\n",
    "        \n",
    "        'real estate': \"\"\"types of properties managed or sold, \n",
    "        common challenges faced in property management or sales, \n",
    "        tools and technologies used for property analysis and valuation.\"\"\",\n",
    "        \n",
    "        'education': \"\"\"levels of education provided (e.g., primary, secondary, tertiary), \n",
    "        common challenges faced in student assessment and curriculum development, \n",
    "        tools and technologies used for educational analysis and research.\"\"\",\n",
    "        \n",
    "        'government': \"\"\"types of public services provided, \n",
    "        common challenges faced in public service delivery and management, \n",
    "        tools and technologies used for data analysis and decision-making.\"\"\",\n",
    "        \n",
    "        'non-profit': \"\"\" types of services or programs provided, \n",
    "        common challenges faced in program delivery and management, \n",
    "        tools and technologies used for data analysis and decision-making.\"\"\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    def __init__(self, temperature=1.0):       \n",
    "        \"\"\"Setup scenario generator bot.\n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Instantiate llm\n",
    "        super().__init__('chat', temperature)\n",
    "            \n",
    "        # Instantiate memory\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "    \n",
    "    def instruct(self, industry, business_size, problem_type, details):\n",
    "        \"\"\"Determine the context of scenario generator. \n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        industry: interested industry, e.g., healthcare, finance, etc.\n",
    "        business_size: large, medium, small.\n",
    "        problem_type: type of machine learning problem, e.g., classification, regression, etc.\n",
    "        details: specific details added to the description.\n",
    "        \"\"\"        \n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.problem_type = problem_type\n",
    "        self.details = ScenarioGenerator.industry_specifics[industry]\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "        ])\n",
    "\n",
    "        self.scen_generator = ConversationChain(memory=self.memory, prompt=prompt, \n",
    "                                          llm=self.llm)\n",
    "        \n",
    "    def step(self):\n",
    "        \"\"\"Interact with the LLM bot. \n",
    "        \"\"\"       \n",
    "        \n",
    "        # 1st stage (draft)\n",
    "        print(\"Generating scenario description: drafting stage...\")\n",
    "        prompt_1st = self._get_1st_stage_prompt()\n",
    "        self.interm_scenario = self.scen_generator.predict(input=prompt_1st)\n",
    "        \n",
    "        # 2nd stage (review and enrich)\n",
    "        print(\"Generating scenario description: refining stage...\")\n",
    "        prompt_2nd = self._get_2nd_stage_prompt()\n",
    "        self.scenario = self.scen_generator.predict(input=prompt_2nd)\n",
    "        print(\"Scenario description generated!\")\n",
    "        \n",
    "        return self.scenario\n",
    "    \n",
    "    \n",
    "    def _get_1st_stage_prompt(self):\n",
    "        \n",
    "        prompt = f\"\"\"For a {self.industry} company of {self.business_size} size focusing on {self.problem_type} problems, \n",
    "        generate a concrete data science project scenario that a data scientist might encounter in real life. \n",
    "        Please provide concrete and specific details relevant to the selected industry and problem type.\n",
    "\n",
    "        For the generated scenario, please provide:\n",
    "        1. A specific and realistic description of a problem faced by the company.\n",
    "        2. The desired outcome that the company is hoping to achieve by solving the problem.\n",
    "        3. A list of the top 3 most relevant data sources that might be available for solving the problem.\n",
    "\n",
    "        Output format:\n",
    "        Problem description: [content of problem description]\n",
    "        Desired outcome: [content of desired outcome]\n",
    "        Available data: [content of available data]\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    \n",
    "    def _get_2nd_stage_prompt(self):\n",
    "        \n",
    "        prompt = f\"\"\"Based on the previously generated scenario, please enrich the problem description \n",
    "        by providing more specific details (such as {self.details}) about the problem.\n",
    "\n",
    "        Output format:\n",
    "        Enriched problem description: [content of enriched problem description]\n",
    "        Desired outcome: [content of desired outcome]\n",
    "        Available data: [content of available data]\n",
    "        \"\"\"\n",
    "        \n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc106d",
   "metadata": {},
   "source": [
    "Quick test of generating the data science case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcabdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating scenario description: drafting stage...\n",
      "Generating scenario description: refining stage...\n",
      "Scenario description generated!\n",
      "Enriched problem description: The medium-sized manufacturing company produces a variety of electronic components such as resistors, capacitors, and diodes used in smartphones, laptops, and other electronic devices. The production process involves multiple steps, including cutting, shaping, cleaning, component placement, soldering, and surface finishing. The company uses machines such as pick and place machines, reflow ovens, wave soldering machines, and automatic optical inspection machines to automate the production process.\n",
      "\n",
      "Despite implementing different quality control measures such as visual inspections and statistical process control, the company is experiencing multiple issues such as surface finish defects, poor solder connections, and misplaced components. These defects result in increased production costs, lower quality products, and customer complaints. The quality control team uses tools and technologies such as magnifying glasses, x-ray machines, and automatic optical inspection machines to detect defects. However, due to the volume and complexity of the production process, they are not able to identify the root cause of defects consistently.\n",
      "\n",
      "Desired outcome: The company aims to reduce the number of defects and increase the overall quality of their electronic components. They want to use data science techniques to identify the sources of defects and find a way to optimize the manufacturing process to minimize them while maintaining production efficiency. By doing this, the company will increase their customer satisfaction and minimize the cost of quality for their products.\n",
      "\n",
      "Available data:\n",
      "1. Process data - The company collects sensor data from the different machines used during manufacturing. This data includes temperature, humidity, pressure, voltage, and other variables that are relevant to the manufacturing process.\n",
      "2. Quality control data - The company has a quality control team that performs visual inspections of the finished products. They note down the defects they have found and the corresponding manufacturing step where the defect occurred.\n",
      "3. Historical production data - The company has a database of past production runs, which includes information about the raw materials used, production time, and production rate. The data also includes information about the machines used, the operators involved, and any maintenance activities performed on the machines.\n"
     ]
    }
   ],
   "source": [
    "# Basic information\n",
    "industry = \"manufacturing\"\n",
    "business_size = \"medium\"\n",
    "problem_type = \"anomaly detection\"\n",
    "details = \"Types of products manufactured, machines used in the production process, \\\n",
    "common issues faced by the company, tools and technologies used for quality control.\"\n",
    "\n",
    "# Instantiate scenario generator\n",
    "scen_generator = ScenarioGenerator(temperature=1.0)\n",
    "scen_generator.instruct(industry, business_size, problem_type, details)\n",
    "\n",
    "# Create the problem description\n",
    "scenario = scen_generator.step()\n",
    "print(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672516a5",
   "metadata": {},
   "source": [
    "### 3. Dual-chatbot module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8657502",
   "metadata": {},
   "source": [
    "#### 3.1 Client chatbot\n",
    "\n",
    "The purpose of the client chatbot is to clarify the situation and give feedback on possible solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21179dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientBot(LLMBot):\n",
    "    \"\"\"Class definition for the client bot, created with LangChain.\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=0.8):       \n",
    "        \"\"\"Setup scenario generator bot.\n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Instantiate llm\n",
    "        super().__init__('chat', temperature)\n",
    "            \n",
    "        # Instantiate memory\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "        \n",
    "        \n",
    "    def instruct(self, industry, business_size, scenario):\n",
    "        \"\"\"Determine the context of client chatbot. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.scenario = scenario\n",
    "        \n",
    "        # Define prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(self._specify_system_message()),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Create conversation chain\n",
    "        self.conversation = ConversationChain(memory=self.memory, prompt=prompt, \n",
    "                                              llm=self.llm, verbose=False)\n",
    "        \n",
    "\n",
    "    def step(self, prompt):\n",
    "        \"\"\"Client chatbot speaks. \n",
    "        \"\"\"\n",
    "        response = self.conversation.predict(input=prompt)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "\n",
    "    def _specify_system_message(self):\n",
    "        \"\"\"Specify the behavior of the client chatbot.\n",
    "        \"\"\"      \n",
    "        \n",
    "        # Prompt\n",
    "        prompt = f\"\"\"You are role-playing a representative from a {self.industry} company of {self.business_size} size and \n",
    "        you are meeting with a data scientist (which is played by another bot), to discuss how to leverage machine learning \n",
    "        to address a problem your company is facing. \n",
    "        \n",
    "        The problem description, desired outcome, and available data are:\n",
    "        {self.scenario}.\n",
    "        \n",
    "        Your ultimate goal is to work with the data scientist to define a clear problem and agree on a suitable data science solution or approach.\n",
    "\n",
    "        Guidelines to keep in mind:\n",
    "        - **Get Straight to the Point**: Start the conversation by directly addressing the problem at hand. There is no need for pleasantries or introductions.\n",
    "        - **Engage in Conversation**: Respond to the data scientist's questions and prompts. Do not provide all the information at once or provide the entire conversation yourself.\n",
    "        - **Clarify and Confirm**: Always make sure to clarify and confirm the problem, desired outcome, and any proposed solutions with the data scientist. \n",
    "        - **Stay in Role**: Your role as a client is to represent your company's needs and work with the data scientist to define a clear problem and agree on a suitable data science solution or approach. Do not try to propose solutions.\n",
    "        - **Provide Information as Needed**: Provide information about the problem, available data, constraints, and requirements as it becomes relevant in the conversation. If the data scientist asks a question and the information was not provided in the problem description, it is okay to improvise and create details that seem reasonable.\n",
    "        - **Collaborate**: Collaborate with the data scientist to clearly define the problem and to consider any proposed solutions or approaches.\n",
    "        \"\"\"\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a54e26",
   "metadata": {},
   "source": [
    "#### 3.2 Data scientist bot\n",
    "\n",
    "The purpose of the data scientist chatbot is understanding the problem in depth and proposing possible solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f31e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScientistBot(LLMBot):\n",
    "    \"\"\"Class definition for the data scientist bot.\"\"\"\n",
    "\n",
    "    def __init__(self, temperature=0.8):   \n",
    "        \"\"\"Setup scenario generator bot.\n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Instantiate llm\n",
    "        super().__init__('chat', temperature)\n",
    "            \n",
    "        # Instantiate memory\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "        \n",
    "    def instruct(self, industry, business_size, problem_type):\n",
    "        \"\"\"Determine the context of data scientist chatbot. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.problem_type = problem_type\n",
    "        \n",
    "        # Define prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(self._specify_system_message()),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Create conversation chain\n",
    "        self.conversation = ConversationChain(memory=self.memory, prompt=prompt, \n",
    "                                              llm=self.llm, verbose=False)\n",
    "        \n",
    "\n",
    "    def step(self, prompt):\n",
    "        \"\"\"Data scientist chatbot speaks. \n",
    "        \"\"\"\n",
    "        response = self.conversation.predict(input=prompt)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "\n",
    "    def _specify_system_message(self):\n",
    "        \"\"\"Specify the behavior of the data scientist chatbot.\n",
    "        \"\"\"      \n",
    "        \n",
    "        # Prompt\n",
    "        prompt = f\"\"\"You are role-playing a data scientist meeting with a representative (which is played by another chatbot) \n",
    "        from a {self.industry} company of {self.business_size} size. They are currently concerned with \n",
    "        a {self.problem_type} problem.\n",
    "\n",
    "        Your ultimate goal is to understand the problem in depth and agree on a suitable data science solution or approach \n",
    "        by engaging in a conversation with the client representative. \n",
    "\n",
    "        Guidelines to keep in mind:\n",
    "        - **Engage in Conversation**: You are only the data scientist. Do not provide the entire conversation yourself.\n",
    "        - **Understand the Problem**: Make sure to ask questions to get a clear and detailed understanding of the problem, the desired outcome, available data, constraints, and requirements.\n",
    "        - **Propose Solutions**: Based on the information provided by the client, suggest possible data science approaches or solutions to address the problem.\n",
    "        - **Consider Constraints**: Be mindful of any constraints that the client may have, such as budget, timeline, or data limitations, and tailor your proposed solutions accordingly.\n",
    "        - **Collaborate**: Collaborate with the client to refine the problem definition, proposed solutions, and ultimately agree on a suitable data science approach.\n",
    "        \"\"\"\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2799b9",
   "metadata": {},
   "source": [
    "#### 3.3 Simulate client-data scientist chatbot conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce5248b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two chatbots\n",
    "client = ClientBot()\n",
    "data_scientist = DataScientistBot()\n",
    "\n",
    "# Specify instructions\n",
    "client.instruct(industry, business_size, scenario)\n",
    "data_scientist.instruct(industry, business_size, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54faaac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë®‚Äçüíº Client: Hello, I'm from a medium-sized manufacturing company that produces electronic components such as resistors, capacitors, and diodes. We are having some issues with defects in our products, and we were hoping to discuss with you how we can leverage machine learning to solve this problem.\n",
      "üë©‚Äçüíª Data Scientist: Of course, I'd be happy to help. Can you give me more details about the types of defects you are experiencing? Are they consistent or do they vary? And how are they currently being detected?\n",
      "\n",
      "\n",
      "\n",
      "üë®‚Äçüíº Client: We are experiencing various defects such as surface finish defects, poor solder connections, and misplaced components. These defects are not consistent and can vary from batch to batch. We are currently detecting the defects through visual inspections, statistical process control, magnifying glasses, x-ray machines, and automatic optical inspection machines, but we are still not able to identify the root cause of the defects consistently.\n",
      "üë©‚Äçüíª Data Scientist: I see. It sounds like you have a complex problem. To understand more about the data involved, can you tell me what kind of data do you have available for analysis? And how long have you been collecting this data?\n",
      "\n",
      "\n",
      "\n",
      "üë®‚Äçüíº Client: Yes, the problem is quite complex. We have several types of data available for analysis. We have process data, which includes sensor data from different machines used during manufacturing such as temperature, humidity, pressure, voltage, and other variables that are relevant to the manufacturing process. We also have quality control data that includes information about defects and the corresponding manufacturing step where the defect occurred. Finally, we have historical production data that covers the raw materials used, production time, production rate, machines used, operators involved, and any maintenance activities performed on the machines. We have been collecting this data for several years.\n",
      "üë©‚Äçüíª Data Scientist: That's helpful. It sounds like you have a lot of data available, which is great. Have you done any analysis on this data before? And do you have any existing models or algorithms in place that might be used for anomaly detection?\n",
      "\n",
      "\n",
      "\n",
      "üë®‚Äçüíº Client: Yes, we have done some analysis on the data before, but it was mostly manual and not very effective in identifying the root cause of the defects. We don't have any existing models or algorithms in place for anomaly detection. We are hoping to use machine learning to help us identify the sources of the defects and optimize the manufacturing process to minimize them.\n",
      "üë©‚Äçüíª Data Scientist: Okay, that makes sense. Based on what you've told me, a possible solution to your problem could be to use unsupervised anomaly detection. Unsupervised anomaly detection is a machine learning technique that can be used to identify patterns or anomalies in data without the need for labeled data. \n",
      "\n",
      "By applying this technique to your process, it will help you identify the root cause of the defects and optimize the manufacturing process to minimize them. However, we would need to apply this technique to your data and see what results we get. \n",
      "\n",
      "What is your timeline for implementing a possible solution? And what is your budget?\n",
      "\n",
      "\n",
      "\n",
      "üë®‚Äçüíº Client: Thank you for the suggestion. We're interested in exploring the unsupervised anomaly detection approach you mentioned. Our timeline is flexible, but we would like to see some progress within the next 6 months. Our budget is also flexible, but we'd like to keep the costs reasonable. What kind of data do you need from us to help with this approach? And what is the general process for implementing it?\n",
      "üë©‚Äçüíª Data Scientist: For the unsupervised anomaly detection approach, we would need access to your historical data, including process data, quality control data, and production data. We will also need to determine which variables are most relevant to the manufacturing process and which variables are contributing to the defects. \n",
      "\n",
      "The general process for implementing this approach involves several steps. First, we will need to clean and preprocess the data to eliminate any noise or irrelevant data. Then, we will use unsupervised learning algorithms to identify patterns or anomalies in the data. Once we have identified the anomalies, we will investigate them to determine the root cause and identify any changes needed to the manufacturing process. Finally, we will use the information we have gathered to optimize the manufacturing process to minimize defects.\n",
      "\n",
      "Based on your timeline and budget constraints, we can start by conducting a feasibility study to determine if unsupervised anomaly detection is a good fit for your problem. The feasibility study will provide a cost estimate and a timeline for implementing the solution. Once we agree on the feasibility study results, we can proceed with the implementation.\n",
      "\n",
      "\n",
      "\n",
      "üë®‚Äçüíº Client: That sounds reasonable. We can provide you with access to our historical data and work with you to identify which variables are most relevant to the manufacturing process. Please provide us with an estimate of the time and cost for the feasibility study, as well as the expected deliverables.\n",
      "üë©‚Äçüíª Data Scientist: Great! For the feasibility study, we estimate that it will take about 4-6 weeks to complete, depending on the complexity of the data and the number of variables involved. The cost of the study will also depend on the complexity of the data and the scope of the project, but we can provide an estimate of $10,000-$15,000.\n",
      "\n",
      "The expected deliverables from the feasibility study would include a report summarizing our findings, including the suitability of unsupervised anomaly detection for your problem, the identification of relevant variables, and a cost and timeline estimate for the full implementation of the solution.\n",
      "\n",
      "Once we agree to proceed with the implementation phase, we will provide a more detailed project plan outlining each step in the process, the expected timeline, and the costs involved. Does this sound reasonable, or do you have any further questions or concerns?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Book-keeping\n",
    "question_list = []\n",
    "answer_list = []\n",
    "\n",
    "# Start conversation\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        question = client.step('Start the conversation')\n",
    "    else:\n",
    "        question = client.step(answer)\n",
    "    question_list.append(question)\n",
    "    print(\"üë®‚Äçüíº Client: \" + question)\n",
    "    \n",
    "    answer = data_scientist.step(question)\n",
    "    answer_list.append(answer)\n",
    "\n",
    "    print(\"üë©‚Äçüíª Data Scientist: \" + answer)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720b375f",
   "metadata": {},
   "source": [
    "### 4. Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd9b72",
   "metadata": {},
   "source": [
    "To further enhance the user's learning experience, it is beneficial to reflect on the conversation and extract the key learning points for the user to review. Those key learning points could include the specific strategy adopted by the data scientist bot in terms of scoping the problem, the various aspects covered/not covered in the conversation, as well as potential follow-up questions or topics for discussion.\n",
    "\n",
    "We adopted a two-stage approach, where we first condense the generated conversation script, and then feed it (together with other relevant information) to the assessor bot to analyze the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714ea5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizerBot(LLMBot):\n",
    "\n",
    "    def __init__(self, temperature=0.8):       \n",
    "        \"\"\"Setup summarizer bot.\n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Instantiate llm\n",
    "        super().__init__('completion', temperature)\n",
    "        \n",
    "    \n",
    "    def instruct(self):\n",
    "        \"\"\"Determine the context of summarizer. \n",
    "        \"\"\"        \n",
    "        \n",
    "        template = \"\"\"Please concisely summarize the following segment of a conversation between a client and \n",
    "        a data scientist discussing a potential data science project:\n",
    "\n",
    "        {conversation}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"conversation\"],\n",
    "        )\n",
    "\n",
    "\n",
    "    def step(self, q_list, a_list):\n",
    "        \"\"\"Summarize the conversation script. \n",
    "        \n",
    "        Args:\n",
    "        ---------\n",
    "        q_list: list of responses from the client bot\n",
    "        a_list: list of responses from the data scientist bot\n",
    "        \"\"\"     \n",
    "        \n",
    "        # Loop over individual rounds\n",
    "        conversation_summary = []\n",
    "        for i, (q, a) in enumerate(zip(q_list, a_list)):\n",
    "            print(f\"Processing {i+1}/{len(q_list)}th conversation round.\")\n",
    "\n",
    "            # Compile one round of conversation\n",
    "            conversation_round = ''\n",
    "            conversation_round += 'Client: ' + q + '\\n\\n'\n",
    "            conversation_round += 'Data scientist: ' + a\n",
    "\n",
    "            response = self.llm.predict(self.prompt.format(conversation=conversation_round))\n",
    "            conversation_summary.append(response)\n",
    "            \n",
    "        return conversation_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743cfa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssessorBot(LLMBot):\n",
    "\n",
    "    def __init__(self, temperature=0.8):       \n",
    "        \"\"\"Setup assessor bot.\n",
    "        \n",
    "        Args:\n",
    "        --------------\n",
    "        temperature: temperature of the LLM.\n",
    "        \"\"\"   \n",
    "        \n",
    "        # Instantiate llm\n",
    "        super().__init__('completion', temperature)\n",
    "        \n",
    "    \n",
    "    def instruct(self, industry, business_size, problem_type):\n",
    "        \"\"\"Determine the context of assessor. \n",
    "        \"\"\"        \n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.problem_type = problem_type\n",
    "        \n",
    "        \n",
    "        template = \"\"\"You are a senior data scientist who has been asked to review a conversation between a data scientist \n",
    "        and a client from a {industry} company of {business_size} size, focusing on a {problem_type} problem. \n",
    "        The client and data scientist are discussing how to define and scope a data science project to address the problem.\n",
    "\n",
    "        Please provide an assessment of the conversation, focusing on the strategy adopted by the data scientist to \n",
    "        define and scope the problem, any potential room for improvement, and any other key points you think are important.\n",
    "        Please organize your response with nicely formatted bulletpoints.\n",
    "\n",
    "        Here is the conversation: \n",
    "        {conversation}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"industry\", \"business_size\", \"problem_type\", \"conversation\"],\n",
    "        )\n",
    "\n",
    "\n",
    "    def step(self, conversation_summary):\n",
    "        \"\"\"Assess the conversation script. \n",
    "        \n",
    "        Args:\n",
    "        ---------\n",
    "        conversation_summary: condensed version of the conversation script.\n",
    "        \"\"\"     \n",
    "        \n",
    "        analysis = self.llm.predict(self.prompt.format(industry=self.industry,\n",
    "                                                        business_size=self.business_size,\n",
    "                                                        problem_type=self.problem_type,\n",
    "                                                        conversation=' '.join(conversation_summary)))\n",
    "        \n",
    "        return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e144c",
   "metadata": {},
   "source": [
    "Test the proposed workflow for analyzing the simulated conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "233e33a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/6th conversation round.\n",
      "Processing 2/6th conversation round.\n",
      "Processing 3/6th conversation round.\n",
      "Processing 4/6th conversation round.\n",
      "Processing 5/6th conversation round.\n",
      "Processing 6/6th conversation round.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the summarizer\n",
    "summarizer = SummarizerBot()\n",
    "summarizer.instruct()\n",
    "\n",
    "# Create conversation summary\n",
    "conversation_summary = summarizer.step(question_list, answer_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113388bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Assessment of the Conversation: \n",
      "‚Ä¢ The data scientist has taken a structured approach to define and scope the problem by asking relevant questions about the manufacturing process, data availability, and existing algorithms. \n",
      "‚Ä¢ The data scientist has proposed an unsupervised anomaly detection approach which is a good fit for the problem and is well-suited for detecting patterns or anomalies without the need for labels, which would be difficult to obtain for this type of problem. \n",
      "‚Ä¢ The data scientist has also proposed a feasibility study to determine if this is the best approach for the client's timeline and budget constraints, providing an estimation of the cost and timeline for the project. \n",
      "‚Ä¢ The data scientist has also proposed a more detailed project plan with timeline and costs for the implementation phase. \n",
      "‚Ä¢ The data scientist could have asked more questions about the client's expectations, such as required accuracy or false positives and false negatives and how the solution would be used. This information would better inform the solution design.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the assessor\n",
    "assessor = AssessorBot()\n",
    "assessor.instruct(industry, business_size, problem_type)\n",
    "\n",
    "# Perform assessment\n",
    "analysis = assessor.step(conversation_summary)\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7350bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
